{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/daniyalatta/ps-s5-09-lightgbm-a-z-best-for-dataset-understand?scriptVersionId=260162362\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"ef78b5b0","metadata":{"papermill":{"duration":0.007857,"end_time":"2025-09-05T16:08:02.671994","exception":false,"start_time":"2025-09-05T16:08:02.664137","status":"completed"},"tags":[]},"source":["\n","### <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:#ffffff; margin:0; font-size:120%; font-family:'Quicksand', sans-serif; background:linear-gradient(to right, #141e30, #243b55); overflow:hidden\"><b>ðŸš€ Your upvote can motivate me to share more useful notebooks!</b>\n","</div>"]},{"cell_type":"markdown","id":"6e2be730","metadata":{"papermill":{"duration":0.006622,"end_time":"2025-09-05T16:08:02.685745","exception":false,"start_time":"2025-09-05T16:08:02.679123","status":"completed"},"tags":[]},"source":["# <div style=\"text-align:center; border-radius:25px 70px; padding:9px; color:#ffffff; margin:0; font-size:120%; font-family:'Quicksand', sans-serif; background:linear-gradient(to right, #141e30, #243b55); overflow:hidden\"><b>ðŸŒŒ  LightGBM Regression Pipeline for Kaggle Playground Series S5E9</b>\n","<p style=\"text-align:center; border-radius:25px 70px; padding:9px; color:#ffffff; margin:0; font-size:120%; font-family:'Quicksand', sans-serif; background:linear-gradient(to right, #141e30, #243b55); overflow:hidden\"> This Python script replicates a machine learning pipeline originally written in R for a regression task using the LightGBM algorithm. The pipeline processes data from the Kaggle Playground Series S5E9 dataset, performs feature engineering, and trains a LightGBM model with 10-fold cross-validation, optimizing for RMSE. The script generates predictions and saves them in the same output formats as the original.</p>\n","</div>\n"]},{"cell_type":"markdown","id":"69e0f797","metadata":{"papermill":{"duration":0.006634,"end_time":"2025-09-05T16:08:02.699145","exception":false,"start_time":"2025-09-05T16:08:02.692511","status":"completed"},"tags":[]},"source":["## Dependencies"]},{"cell_type":"code","execution_count":1,"id":"444736a4","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:08:02.715548Z","iopub.status.busy":"2025-09-05T16:08:02.714692Z","iopub.status.idle":"2025-09-05T16:08:12.851738Z","shell.execute_reply":"2025-09-05T16:08:12.850715Z"},"papermill":{"duration":10.146643,"end_time":"2025-09-05T16:08:12.853383","exception":false,"start_time":"2025-09-05T16:08:02.70674","status":"completed"},"tags":[]},"outputs":[],"source":["# Dependencies\n","import pandas as pd\n","import numpy as np\n","from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.compose import ColumnTransformer\n","import gc\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"7712912f","metadata":{"papermill":{"duration":0.006461,"end_time":"2025-09-05T16:08:12.866859","exception":false,"start_time":"2025-09-05T16:08:12.860398","status":"completed"},"tags":[]},"source":["## Utility Functions\n","### Free Memory\n","### Clears memory to optimize performance."]},{"cell_type":"code","execution_count":2,"id":"a421103e","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-09-05T16:08:12.881883Z","iopub.status.busy":"2025-09-05T16:08:12.881313Z","iopub.status.idle":"2025-09-05T16:08:12.886165Z","shell.execute_reply":"2025-09-05T16:08:12.885174Z"},"papermill":{"duration":0.014106,"end_time":"2025-09-05T16:08:12.887678","exception":false,"start_time":"2025-09-05T16:08:12.873572","status":"completed"},"tags":[]},"outputs":[],"source":["# Free Memory\n","def free():\n","    gc.collect()"]},{"cell_type":"markdown","id":"81f7ad1d","metadata":{"papermill":{"duration":0.006536,"end_time":"2025-09-05T16:08:12.901027","exception":false,"start_time":"2025-09-05T16:08:12.894491","status":"completed"},"tags":[]},"source":["### Calculate Mode\n","Computes the mode of a series, handling missing values."]},{"cell_type":"code","execution_count":3,"id":"27abec89","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:08:12.915559Z","iopub.status.busy":"2025-09-05T16:08:12.915275Z","iopub.status.idle":"2025-09-05T16:08:12.920026Z","shell.execute_reply":"2025-09-05T16:08:12.919018Z"},"papermill":{"duration":0.013814,"end_time":"2025-09-05T16:08:12.921447","exception":false,"start_time":"2025-09-05T16:08:12.907633","status":"completed"},"tags":[]},"outputs":[],"source":["# Calculate Mode\n","def calc_mode(x):\n","    x = x.dropna()\n","    if len(x) == 0:\n","        return np.nan\n","    return pd.Series(x).mode()[0]"]},{"cell_type":"markdown","id":"48bef94e","metadata":{"papermill":{"duration":0.006401,"end_time":"2025-09-05T16:08:12.934562","exception":false,"start_time":"2025-09-05T16:08:12.928161","status":"completed"},"tags":[]},"source":["### RMSE Metric\n","Calculates the Root Mean Squared Error (RMSE) for evaluation."]},{"cell_type":"code","execution_count":4,"id":"4ae4957b","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:08:12.948866Z","iopub.status.busy":"2025-09-05T16:08:12.948573Z","iopub.status.idle":"2025-09-05T16:08:12.953217Z","shell.execute_reply":"2025-09-05T16:08:12.952338Z"},"papermill":{"duration":0.013799,"end_time":"2025-09-05T16:08:12.954882","exception":false,"start_time":"2025-09-05T16:08:12.941083","status":"completed"},"tags":[]},"outputs":[],"source":["# RMSE Metric\n","def rmse(y_true, y_pred):\n","    return np.sqrt(mean_squared_error(y_true, y_pred))"]},{"cell_type":"markdown","id":"17d2f5c7","metadata":{"papermill":{"duration":0.006666,"end_time":"2025-09-05T16:08:12.968379","exception":false,"start_time":"2025-09-05T16:08:12.961713","status":"completed"},"tags":[]},"source":["## Data Loading\n","Loads the training, test, and sample submission files from the Kaggle dataset."]},{"cell_type":"code","execution_count":5,"id":"2f448ba0","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:08:12.982932Z","iopub.status.busy":"2025-09-05T16:08:12.98262Z","iopub.status.idle":"2025-09-05T16:08:15.224742Z","shell.execute_reply":"2025-09-05T16:08:15.22371Z"},"papermill":{"duration":2.251801,"end_time":"2025-09-05T16:08:15.226837","exception":false,"start_time":"2025-09-05T16:08:12.975036","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Raw train data shape: (524164, 11)\n","Raw train data non-NaN counts: id                           524164\n","RhythmScore                  524164\n","AudioLoudness                524164\n","VocalContent                 524164\n","AcousticQuality              524164\n","InstrumentalScore            524164\n","LivePerformanceLikelihood    524164\n","MoodScore                    524164\n","TrackDurationMs              524164\n","Energy                       524164\n","BeatsPerMinute               524164\n","dtype: int64\n","Raw train data types: id                             int64\n","RhythmScore                  float64\n","AudioLoudness                float64\n","VocalContent                 float64\n","AcousticQuality              float64\n","InstrumentalScore            float64\n","LivePerformanceLikelihood    float64\n","MoodScore                    float64\n","TrackDurationMs              float64\n","Energy                       float64\n","BeatsPerMinute               float64\n","dtype: object\n"]}],"source":["# Data Loading\n","PATH = \"/kaggle/input/playground-series-s5e9/\"\n","dt = pd.read_csv(f\"{PATH}train.csv\")\n","dtest = pd.read_csv(f\"{PATH}test.csv\")\n","sub = pd.read_csv(f\"{PATH}sample_submission.csv\")\n","sub_temp = sub.iloc[:, 1].copy()\n","# Debug: Inspect raw data\n","print(\"Raw train data shape:\", dt.shape)\n","print(\"Raw train data non-NaN counts:\", dt.notna().sum())\n","print(\"Raw train data types:\", dt.dtypes)"]},{"cell_type":"markdown","id":"aa6f3fa5","metadata":{"papermill":{"duration":0.006958,"end_time":"2025-09-05T16:08:15.241084","exception":false,"start_time":"2025-09-05T16:08:15.234126","status":"completed"},"tags":[]},"source":["## Data Preprocessing\n","### Identify Target\n","Extracts the target variable from the training set and computes the maximum value per row."]},{"cell_type":"code","execution_count":6,"id":"ee088022","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:08:15.256779Z","iopub.status.busy":"2025-09-05T16:08:15.256455Z","iopub.status.idle":"2025-09-05T16:08:15.371707Z","shell.execute_reply":"2025-09-05T16:08:15.370469Z"},"papermill":{"duration":0.126004,"end_time":"2025-09-05T16:08:15.373928","exception":false,"start_time":"2025-09-05T16:08:15.247924","status":"completed"},"tags":[]},"outputs":[],"source":["# Identify Target\n","target = [col for col in dt.columns if col not in dtest.columns]\n","Y = dt[target].max(axis=1)\n","dt = dt.drop(columns=target)"]},{"cell_type":"markdown","id":"2af7eb3c","metadata":{"papermill":{"duration":0.009782,"end_time":"2025-09-05T16:08:15.395146","exception":false,"start_time":"2025-09-05T16:08:15.385364","status":"completed"},"tags":[]},"source":["### Merge Train and Test\n","Combines train and test datasets for consistent preprocessing."]},{"cell_type":"code","execution_count":7,"id":"a878423e","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:08:15.418005Z","iopub.status.busy":"2025-09-05T16:08:15.416789Z","iopub.status.idle":"2025-09-05T16:08:15.46711Z","shell.execute_reply":"2025-09-05T16:08:15.466038Z"},"papermill":{"duration":0.062703,"end_time":"2025-09-05T16:08:15.46899","exception":false,"start_time":"2025-09-05T16:08:15.406287","status":"completed"},"tags":[]},"outputs":[],"source":["# Merge Train and Test\n","dt['fuente'] = 'train'\n","dtest['fuente'] = 'test'\n","dt_total = pd.concat([dt, dtest], ignore_index=True)"]},{"cell_type":"markdown","id":"bfdb4495","metadata":{"papermill":{"duration":0.00689,"end_time":"2025-09-05T16:08:15.483006","exception":false,"start_time":"2025-09-05T16:08:15.476116","status":"completed"},"tags":[]},"source":["### Remove Duplicated Columns\n","Identifies and removes columns that are duplicates."]},{"cell_type":"code","execution_count":8,"id":"c9687795","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:08:15.498934Z","iopub.status.busy":"2025-09-05T16:08:15.498546Z","iopub.status.idle":"2025-09-05T16:26:37.63472Z","shell.execute_reply":"2025-09-05T16:26:37.633771Z"},"papermill":{"duration":1102.146621,"end_time":"2025-09-05T16:26:37.636482","exception":false,"start_time":"2025-09-05T16:08:15.489861","status":"completed"},"tags":[]},"outputs":[],"source":["# Remove Duplicated Columns\n","cols_duplicated = dt_total.columns[dt_total.T.duplicated()].tolist()\n","if cols_duplicated:\n","    dt_total = dt_total.drop(columns=cols_duplicated)\n","    print(f\"Removed duplicated columns: {cols_duplicated}\")"]},{"cell_type":"markdown","id":"54e3e342","metadata":{"papermill":{"duration":0.007492,"end_time":"2025-09-05T16:26:37.651701","exception":false,"start_time":"2025-09-05T16:26:37.644209","status":"completed"},"tags":[]},"source":["### Remove High-Null Columns\n","Drops columns with 0.95% or more missing values."]},{"cell_type":"code","execution_count":9,"id":"8269ea53","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:26:37.666852Z","iopub.status.busy":"2025-09-05T16:26:37.666542Z","iopub.status.idle":"2025-09-05T16:26:37.729386Z","shell.execute_reply":"2025-09-05T16:26:37.728377Z"},"papermill":{"duration":0.07257,"end_time":"2025-09-05T16:26:37.731223","exception":false,"start_time":"2025-09-05T16:26:37.658653","status":"completed"},"tags":[]},"outputs":[],"source":["# Remove High-Null Columns\n","null_cols = dt_total.columns[dt_total.isnull().mean() >= 0.95].tolist()\n","if null_cols:\n","    dt_total = dt_total.drop(columns=null_cols)\n","    print(f\"Removed columns with >= 95% nulls: {null_cols}\")"]},{"cell_type":"markdown","id":"438e265a","metadata":{"papermill":{"duration":0.006835,"end_time":"2025-09-05T16:26:37.745151","exception":false,"start_time":"2025-09-05T16:26:37.738316","status":"completed"},"tags":[]},"source":["### Remove Single-Value Columns\n","Removes columns with only one unique value."]},{"cell_type":"code","execution_count":10,"id":"970ab6b1","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:26:37.762013Z","iopub.status.busy":"2025-09-05T16:26:37.761677Z","iopub.status.idle":"2025-09-05T16:26:38.093006Z","shell.execute_reply":"2025-09-05T16:26:38.09205Z"},"papermill":{"duration":0.342597,"end_time":"2025-09-05T16:26:38.094701","exception":false,"start_time":"2025-09-05T16:26:37.752104","status":"completed"},"tags":[]},"outputs":[],"source":["# Remove Single-Value Columns\n","n_unique = dt_total.nunique()\n","one_value_cols = n_unique[n_unique == 1].index.tolist()\n","if one_value_cols:\n","    dt_total = dt_total.drop(columns=one_value_cols)\n","    print(f\"Removed columns with one unique value: {one_value_cols}\")"]},{"cell_type":"markdown","id":"78e45ed5","metadata":{"papermill":{"duration":0.006643,"end_time":"2025-09-05T16:26:38.10871","exception":false,"start_time":"2025-09-05T16:26:38.102067","status":"completed"},"tags":[]},"source":["### Add Null Count Feature\n","Adds a column counting missing values per row."]},{"cell_type":"code","execution_count":11,"id":"8b0cbb41","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:26:38.1237Z","iopub.status.busy":"2025-09-05T16:26:38.1234Z","iopub.status.idle":"2025-09-05T16:26:38.185934Z","shell.execute_reply":"2025-09-05T16:26:38.184854Z"},"papermill":{"duration":0.072083,"end_time":"2025-09-05T16:26:38.187643","exception":false,"start_time":"2025-09-05T16:26:38.11556","status":"completed"},"tags":[]},"outputs":[],"source":["# Add Null Count Feature\n","if dt_total.isnull().sum().sum() > 0:\n","    dt_total['FilasNulas'] = dt_total.isnull().sum(axis=1)"]},{"cell_type":"markdown","id":"7dab3069","metadata":{"papermill":{"duration":0.006598,"end_time":"2025-09-05T16:26:38.201727","exception":false,"start_time":"2025-09-05T16:26:38.195129","status":"completed"},"tags":[]},"source":["### Convert Potential Numeric Columns to Numeric Type"]},{"cell_type":"code","execution_count":12,"id":"3dd730a4","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:26:38.217488Z","iopub.status.busy":"2025-09-05T16:26:38.217193Z","iopub.status.idle":"2025-09-05T16:26:38.236573Z","shell.execute_reply":"2025-09-05T16:26:38.235741Z"},"papermill":{"duration":0.029143,"end_time":"2025-09-05T16:26:38.238354","exception":false,"start_time":"2025-09-05T16:26:38.209211","status":"completed"},"tags":[]},"outputs":[],"source":["# Convert potential numeric columns to numeric type\n","for col in dt_total.columns:\n","    if col not in ['id', 'fuente']:\n","        try:\n","            dt_total[col] = pd.to_numeric(dt_total[col], errors='coerce')\n","        except:\n","            pass"]},{"cell_type":"markdown","id":"a84413f4","metadata":{"papermill":{"duration":0.00682,"end_time":"2025-09-05T16:26:38.252499","exception":false,"start_time":"2025-09-05T16:26:38.245679","status":"completed"},"tags":[]},"source":["### Encode Categorical Columns\n","Converts categorical columns to integer codes using LabelEncoder."]},{"cell_type":"code","execution_count":13,"id":"506a67b4","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:26:38.267658Z","iopub.status.busy":"2025-09-05T16:26:38.267301Z","iopub.status.idle":"2025-09-05T16:26:38.277549Z","shell.execute_reply":"2025-09-05T16:26:38.276746Z"},"papermill":{"duration":0.019815,"end_time":"2025-09-05T16:26:38.27928","exception":false,"start_time":"2025-09-05T16:26:38.259465","status":"completed"},"tags":[]},"outputs":[],"source":["# Encode Categorical Columns\n","cat_cols = dt_total.select_dtypes(include=['object']).columns.tolist()\n","cat_cols = [col for col in cat_cols if col != 'fuente']  # Exclude 'fuente' from encoding\n","for col in cat_cols:\n","    dt_total[col] = LabelEncoder().fit_transform(dt_total[col].astype(str))"]},{"cell_type":"markdown","id":"924ddf86","metadata":{"papermill":{"duration":0.006561,"end_time":"2025-09-05T16:26:38.293056","exception":false,"start_time":"2025-09-05T16:26:38.286495","status":"completed"},"tags":[]},"source":["### Remove Low-Variance Features\n","Drops features where 99.9% or more of the values are identical."]},{"cell_type":"code","execution_count":14,"id":"d98fbf98","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:26:38.30826Z","iopub.status.busy":"2025-09-05T16:26:38.30791Z","iopub.status.idle":"2025-09-05T16:26:38.925336Z","shell.execute_reply":"2025-09-05T16:26:38.924129Z"},"papermill":{"duration":0.627097,"end_time":"2025-09-05T16:26:38.927072","exception":false,"start_time":"2025-09-05T16:26:38.299975","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Total columns removed: 0\n"]}],"source":["# Remove Low-Variance Features\n","cols_total = dt_total.columns[3:]\n","i_cols_borradas = 0\n","for c in cols_total:\n","    mode_val = calc_mode(dt_total[c])\n","    prc_repetido = (dt_total[c] == mode_val).mean()\n","    if prc_repetido >= 0.95:\n","        print(f\"Removing {c} with repeated value proportion {prc_repetido:.3f}\")\n","        dt_total = dt_total.drop(columns=c)\n","        i_cols_borradas += 1\n","print(f\"Total columns removed: {i_cols_borradas}\")"]},{"cell_type":"markdown","id":"69c99276","metadata":{"papermill":{"duration":0.006905,"end_time":"2025-09-05T16:26:38.941335","exception":false,"start_time":"2025-09-05T16:26:38.93443","status":"completed"},"tags":[]},"source":["### Frequency Encoding\n","Applies frequency encoding to categorical features with 15 or fewer unique values."]},{"cell_type":"code","execution_count":15,"id":"ad0c52ad","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:26:38.956859Z","iopub.status.busy":"2025-09-05T16:26:38.95658Z","iopub.status.idle":"2025-09-05T16:26:39.282986Z","shell.execute_reply":"2025-09-05T16:26:39.281833Z"},"papermill":{"duration":0.336245,"end_time":"2025-09-05T16:26:39.284764","exception":false,"start_time":"2025-09-05T16:26:38.948519","status":"completed"},"tags":[]},"outputs":[],"source":["# Frequency Encoding\n","n_categories = dt_total[cols_total].nunique()\n","cat_features = n_categories[n_categories <= 15].index.tolist()\n","for c in cat_features:\n","    freq = dt_total[c].value_counts().to_dict()\n","    dt_total[f\"{c}_FreqEnc\"] = dt_total[c].map(freq)"]},{"cell_type":"markdown","id":"2aed0f55","metadata":{"papermill":{"duration":0.006675,"end_time":"2025-09-05T16:26:39.298646","exception":false,"start_time":"2025-09-05T16:26:39.291971","status":"completed"},"tags":[]},"source":["### Handle Missing Values\n","Imputes missing values with the median of each column."]},{"cell_type":"code","execution_count":16,"id":"26548ace","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:26:39.313925Z","iopub.status.busy":"2025-09-05T16:26:39.31342Z","iopub.status.idle":"2025-09-05T16:26:39.378336Z","shell.execute_reply":"2025-09-05T16:26:39.377414Z"},"papermill":{"duration":0.074512,"end_time":"2025-09-05T16:26:39.380117","exception":false,"start_time":"2025-09-05T16:26:39.305605","status":"completed"},"tags":[]},"outputs":[],"source":["# Handle Missing Values\n","null_cols = dt_total.columns[dt_total.isnull().sum() > 0]\n","for c in null_cols:\n","    if dt_total[c].notna().sum() > 0:  # If column has at least one non-NaN value\n","        median_val = dt_total[c].median()\n","        dt_total[c].fillna(median_val, inplace=True)\n","    else:  # If column is entirely NaN\n","        print(f\"Column {c} is entirely NaN, imputing with 0\")\n","        dt_total[c].fillna(0, inplace=True)"]},{"cell_type":"markdown","id":"1aeb1470","metadata":{"papermill":{"duration":0.00713,"end_time":"2025-09-05T16:26:39.395263","exception":false,"start_time":"2025-09-05T16:26:39.388133","status":"completed"},"tags":[]},"source":["### Split Train and Test\n","Separates the combined dataset back into train and test sets."]},{"cell_type":"code","execution_count":17,"id":"911dd965","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:26:39.41061Z","iopub.status.busy":"2025-09-05T16:26:39.410295Z","iopub.status.idle":"2025-09-05T16:26:39.598796Z","shell.execute_reply":"2025-09-05T16:26:39.597681Z"},"papermill":{"duration":0.198444,"end_time":"2025-09-05T16:26:39.600707","exception":false,"start_time":"2025-09-05T16:26:39.402263","status":"completed"},"tags":[]},"outputs":[],"source":["# Split Train and Test\n","dt = dt_total[dt_total['fuente'] == 'train'].drop(columns='fuente')\n","dtest = dt_total[dt_total['fuente'] == 'test'].drop(columns='fuente')"]},{"cell_type":"markdown","id":"3141dd00","metadata":{"papermill":{"duration":0.006705,"end_time":"2025-09-05T16:26:39.614592","exception":false,"start_time":"2025-09-05T16:26:39.607887","status":"completed"},"tags":[]},"source":["### Preprocessing Pipeline\n","Normalizes numeric columns using StandardScaler."]},{"cell_type":"code","execution_count":18,"id":"8dafaca2","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:26:39.630313Z","iopub.status.busy":"2025-09-05T16:26:39.630005Z","iopub.status.idle":"2025-09-05T16:26:39.980236Z","shell.execute_reply":"2025-09-05T16:26:39.979452Z"},"papermill":{"duration":0.359991,"end_time":"2025-09-05T16:26:39.982114","exception":false,"start_time":"2025-09-05T16:26:39.622123","status":"completed"},"tags":[]},"outputs":[],"source":["# Preprocessing Pipeline\n","numeric_cols = dt.select_dtypes(include=[np.number]).columns.drop(['id'], errors='ignore')\n","numeric_cols = [col for col in numeric_cols if dt[col].notna().sum() > 0]\n","if len(numeric_cols) > 0:\n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            ('num', StandardScaler(), numeric_cols)\n","        ],\n","        remainder='passthrough'\n","    )\n","    dt_processed = preprocessor.fit_transform(dt)\n","    dtest_processed = preprocessor.transform(dtest)\n","    all_cols = numeric_cols + [col for col in dt.columns if col not in numeric_cols]\n","    dt = pd.DataFrame(dt_processed, columns=all_cols)\n","    dtest = pd.DataFrame(dtest_processed, columns=all_cols)\n","else:\n","    print(\"No valid numeric columns to scale. Using all columns as-is.\")\n","    dt = dt.copy()\n","    dtest = dtest.copy()\n","    if dt.drop(columns=['id'], errors='ignore').shape[1] == 0:\n","        raise ValueError(\"No features available for modeling after preprocessing.\")\n","dt['id'] = dt['id'].astype(int)\n","dtest['id'] = dtest['id'].astype(int)"]},{"cell_type":"markdown","id":"ca131369","metadata":{"papermill":{"duration":0.006716,"end_time":"2025-09-05T16:26:39.996092","exception":false,"start_time":"2025-09-05T16:26:39.989376","status":"completed"},"tags":[]},"source":["## Model Training and Prediction\n","### Setup\n","Initializes out-of-fold (OOF) predictions and submission DataFrames."]},{"cell_type":"code","execution_count":19,"id":"72fe13fb","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:26:40.011468Z","iopub.status.busy":"2025-09-05T16:26:40.011158Z","iopub.status.idle":"2025-09-05T16:26:40.018591Z","shell.execute_reply":"2025-09-05T16:26:40.017215Z"},"papermill":{"duration":0.017302,"end_time":"2025-09-05T16:26:40.020447","exception":false,"start_time":"2025-09-05T16:26:40.003145","status":"completed"},"tags":[]},"outputs":[],"source":["# Setup\n","oof = pd.DataFrame({'target': Y})\n","sub_seeds = sub.copy()\n","sub_seeds.iloc[:, 1:] = 0\n","scores = []\n","SEEDS = [1975, 2000, 2503, 1511, 2604]"]},{"cell_type":"markdown","id":"321dbb24","metadata":{"papermill":{"duration":0.007519,"end_time":"2025-09-05T16:26:40.035184","exception":false,"start_time":"2025-09-05T16:26:40.027665","status":"completed"},"tags":[]},"source":["### K-Fold Cross-Validation\n","Trains LightGBM models for each seed and fold, saving predictions and feature importances."]},{"cell_type":"code","execution_count":20,"id":"5dadfaae","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:26:40.052355Z","iopub.status.busy":"2025-09-05T16:26:40.052039Z","iopub.status.idle":"2025-09-05T16:42:26.580133Z","shell.execute_reply":"2025-09-05T16:42:26.578738Z"},"papermill":{"duration":946.539598,"end_time":"2025-09-05T16:42:26.581847","exception":false,"start_time":"2025-09-05T16:26:40.042249","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Seed: 1975\n","\n","LGBM Fold 1 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024131 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.035388\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4407\tvalid_1's rmse: 26.4797\n","[500]\ttraining's rmse: 26.4241\tvalid_1's rmse: 26.4799\n","[750]\ttraining's rmse: 26.4087\tvalid_1's rmse: 26.4809\n","Early stopping, best iteration is:\n","[296]\ttraining's rmse: 26.4377\tvalid_1's rmse: 26.4795\n","LGBM Fold 1 RMSE: 26.4795, Avg RMSE: 26.4795\n","\n","LGBM Fold 2 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025064 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.040076\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4425\tvalid_1's rmse: 26.4692\n","[500]\ttraining's rmse: 26.4259\tvalid_1's rmse: 26.4696\n","[750]\ttraining's rmse: 26.4106\tvalid_1's rmse: 26.4697\n","Early stopping, best iteration is:\n","[275]\ttraining's rmse: 26.4408\tvalid_1's rmse: 26.469\n","LGBM Fold 2 RMSE: 26.4690, Avg RMSE: 26.4742\n","\n","LGBM Fold 3 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022930 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.035579\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.441\tvalid_1's rmse: 26.4804\n","[500]\ttraining's rmse: 26.4245\tvalid_1's rmse: 26.4795\n","[750]\ttraining's rmse: 26.4097\tvalid_1's rmse: 26.4787\n","[1000]\ttraining's rmse: 26.3957\tvalid_1's rmse: 26.4789\n","[1250]\ttraining's rmse: 26.3819\tvalid_1's rmse: 26.4794\n","Early stopping, best iteration is:\n","[751]\ttraining's rmse: 26.4097\tvalid_1's rmse: 26.4786\n","LGBM Fold 3 RMSE: 26.4786, Avg RMSE: 26.4757\n","\n","LGBM Fold 4 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023063 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.050644\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4558\tvalid_1's rmse: 26.3484\n","[500]\ttraining's rmse: 26.4396\tvalid_1's rmse: 26.349\n","[750]\ttraining's rmse: 26.4247\tvalid_1's rmse: 26.3501\n","Early stopping, best iteration is:\n","[301]\ttraining's rmse: 26.4525\tvalid_1's rmse: 26.3483\n","LGBM Fold 4 RMSE: 26.3483, Avg RMSE: 26.4439\n","\n","LGBM Fold 5 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021874 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.044157\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4419\tvalid_1's rmse: 26.473\n","[500]\ttraining's rmse: 26.4253\tvalid_1's rmse: 26.4725\n","[750]\ttraining's rmse: 26.4105\tvalid_1's rmse: 26.4724\n","[1000]\ttraining's rmse: 26.3965\tvalid_1's rmse: 26.4729\n","Early stopping, best iteration is:\n","[635]\ttraining's rmse: 26.4173\tvalid_1's rmse: 26.4723\n","LGBM Fold 5 RMSE: 26.4723, Avg RMSE: 26.4496\n","\n","LGBM Fold 6 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022179 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.033556\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4524\tvalid_1's rmse: 26.3808\n","[500]\ttraining's rmse: 26.4359\tvalid_1's rmse: 26.3795\n","[750]\ttraining's rmse: 26.421\tvalid_1's rmse: 26.3806\n","Early stopping, best iteration is:\n","[462]\ttraining's rmse: 26.4383\tvalid_1's rmse: 26.3793\n","LGBM Fold 6 RMSE: 26.3793, Avg RMSE: 26.4378\n","\n","LGBM Fold 7 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030765 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.031945\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4385\tvalid_1's rmse: 26.5055\n","[500]\ttraining's rmse: 26.4221\tvalid_1's rmse: 26.5051\n","[750]\ttraining's rmse: 26.4072\tvalid_1's rmse: 26.5056\n","[1000]\ttraining's rmse: 26.3928\tvalid_1's rmse: 26.506\n","Early stopping, best iteration is:\n","[563]\ttraining's rmse: 26.4183\tvalid_1's rmse: 26.505\n","LGBM Fold 7 RMSE: 26.5050, Avg RMSE: 26.4474\n","\n","LGBM Fold 8 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033642 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.018417\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4239\tvalid_1's rmse: 26.6333\n","[500]\ttraining's rmse: 26.4073\tvalid_1's rmse: 26.6318\n","[750]\ttraining's rmse: 26.3922\tvalid_1's rmse: 26.6312\n","[1000]\ttraining's rmse: 26.3778\tvalid_1's rmse: 26.6313\n","[1250]\ttraining's rmse: 26.3638\tvalid_1's rmse: 26.6318\n","Early stopping, best iteration is:\n","[926]\ttraining's rmse: 26.3819\tvalid_1's rmse: 26.6312\n","LGBM Fold 8 RMSE: 26.6312, Avg RMSE: 26.4704\n","\n","LGBM Fold 9 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023789 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.033503\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4562\tvalid_1's rmse: 26.3425\n","[500]\ttraining's rmse: 26.4395\tvalid_1's rmse: 26.3423\n","[750]\ttraining's rmse: 26.4245\tvalid_1's rmse: 26.343\n","[1000]\ttraining's rmse: 26.4102\tvalid_1's rmse: 26.3441\n","Early stopping, best iteration is:\n","[594]\ttraining's rmse: 26.4338\tvalid_1's rmse: 26.3422\n","LGBM Fold 9 RMSE: 26.3422, Avg RMSE: 26.4561\n","\n","LGBM Fold 10 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042275 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.025728\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4416\tvalid_1's rmse: 26.4772\n","[500]\ttraining's rmse: 26.4251\tvalid_1's rmse: 26.4765\n","[750]\ttraining's rmse: 26.4102\tvalid_1's rmse: 26.4768\n","[1000]\ttraining's rmse: 26.3964\tvalid_1's rmse: 26.4775\n","Early stopping, best iteration is:\n","[575]\ttraining's rmse: 26.4205\tvalid_1's rmse: 26.4763\n","LGBM Fold 10 RMSE: 26.4763, Avg RMSE: 26.4582\n","AUC LGBM Seed 1975: 26.4582\n","\n","Seed: 2000\n","\n","LGBM Fold 1 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022129 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.009324\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4328\tvalid_1's rmse: 26.5542\n","[500]\ttraining's rmse: 26.4161\tvalid_1's rmse: 26.5538\n","[750]\ttraining's rmse: 26.401\tvalid_1's rmse: 26.5535\n","[1000]\ttraining's rmse: 26.3866\tvalid_1's rmse: 26.553\n","[1250]\ttraining's rmse: 26.3726\tvalid_1's rmse: 26.5536\n","[1500]\ttraining's rmse: 26.3589\tvalid_1's rmse: 26.5542\n","Early stopping, best iteration is:\n","[1034]\ttraining's rmse: 26.3846\tvalid_1's rmse: 26.553\n","LGBM Fold 1 RMSE: 26.5530, Avg RMSE: 26.4668\n","\n","LGBM Fold 2 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022801 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.032113\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4545\tvalid_1's rmse: 26.3633\n","[500]\ttraining's rmse: 26.4382\tvalid_1's rmse: 26.3609\n","[750]\ttraining's rmse: 26.4234\tvalid_1's rmse: 26.3609\n","[1000]\ttraining's rmse: 26.4087\tvalid_1's rmse: 26.3611\n","Early stopping, best iteration is:\n","[674]\ttraining's rmse: 26.4279\tvalid_1's rmse: 26.3607\n","LGBM Fold 2 RMSE: 26.3607, Avg RMSE: 26.4579\n","\n","LGBM Fold 3 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021289 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.031037\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4435\tvalid_1's rmse: 26.4569\n","[500]\ttraining's rmse: 26.427\tvalid_1's rmse: 26.457\n","[750]\ttraining's rmse: 26.4118\tvalid_1's rmse: 26.4574\n","Early stopping, best iteration is:\n","[407]\ttraining's rmse: 26.433\tvalid_1's rmse: 26.4568\n","LGBM Fold 3 RMSE: 26.4568, Avg RMSE: 26.4579\n","\n","LGBM Fold 4 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022856 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.049930\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4255\tvalid_1's rmse: 26.6197\n","[500]\ttraining's rmse: 26.4092\tvalid_1's rmse: 26.6189\n","[750]\ttraining's rmse: 26.3942\tvalid_1's rmse: 26.6197\n","[1000]\ttraining's rmse: 26.38\tvalid_1's rmse: 26.6203\n","Early stopping, best iteration is:\n","[506]\ttraining's rmse: 26.4088\tvalid_1's rmse: 26.6189\n","LGBM Fold 4 RMSE: 26.6189, Avg RMSE: 26.4694\n","\n","LGBM Fold 5 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022256 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.044209\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4429\tvalid_1's rmse: 26.4638\n","[500]\ttraining's rmse: 26.4265\tvalid_1's rmse: 26.4633\n","[750]\ttraining's rmse: 26.4114\tvalid_1's rmse: 26.4633\n","[1000]\ttraining's rmse: 26.397\tvalid_1's rmse: 26.4634\n","Early stopping, best iteration is:\n","[633]\ttraining's rmse: 26.4183\tvalid_1's rmse: 26.463\n","LGBM Fold 5 RMSE: 26.4630, Avg RMSE: 26.4689\n","\n","LGBM Fold 6 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021863 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.043301\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.449\tvalid_1's rmse: 26.4068\n","[500]\ttraining's rmse: 26.4325\tvalid_1's rmse: 26.4071\n","[750]\ttraining's rmse: 26.4177\tvalid_1's rmse: 26.408\n","Early stopping, best iteration is:\n","[325]\ttraining's rmse: 26.4439\tvalid_1's rmse: 26.4064\n","LGBM Fold 6 RMSE: 26.4064, Avg RMSE: 26.4650\n","\n","LGBM Fold 7 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023135 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.007222\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4448\tvalid_1's rmse: 26.4502\n","[500]\ttraining's rmse: 26.4282\tvalid_1's rmse: 26.4473\n","[750]\ttraining's rmse: 26.4129\tvalid_1's rmse: 26.4474\n","[1000]\ttraining's rmse: 26.3987\tvalid_1's rmse: 26.4478\n","Early stopping, best iteration is:\n","[509]\ttraining's rmse: 26.4277\tvalid_1's rmse: 26.4472\n","LGBM Fold 7 RMSE: 26.4472, Avg RMSE: 26.4640\n","\n","LGBM Fold 8 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022557 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.037644\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4556\tvalid_1's rmse: 26.3459\n","[500]\ttraining's rmse: 26.4391\tvalid_1's rmse: 26.3446\n","[750]\ttraining's rmse: 26.4241\tvalid_1's rmse: 26.3444\n","[1000]\ttraining's rmse: 26.4096\tvalid_1's rmse: 26.3453\n","Early stopping, best iteration is:\n","[637]\ttraining's rmse: 26.4308\tvalid_1's rmse: 26.3442\n","LGBM Fold 8 RMSE: 26.3442, Avg RMSE: 26.4573\n","\n","LGBM Fold 9 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064084 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.044864\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4512\tvalid_1's rmse: 26.3902\n","[500]\ttraining's rmse: 26.4343\tvalid_1's rmse: 26.3901\n","[750]\ttraining's rmse: 26.4191\tvalid_1's rmse: 26.3899\n","Early stopping, best iteration is:\n","[356]\ttraining's rmse: 26.4438\tvalid_1's rmse: 26.3894\n","LGBM Fold 9 RMSE: 26.3894, Avg RMSE: 26.4538\n","\n","LGBM Fold 10 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023289 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.049350\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4346\tvalid_1's rmse: 26.5366\n","[500]\ttraining's rmse: 26.4179\tvalid_1's rmse: 26.5369\n","Early stopping, best iteration is:\n","[234]\ttraining's rmse: 26.4357\tvalid_1's rmse: 26.5366\n","LGBM Fold 10 RMSE: 26.5366, Avg RMSE: 26.4579\n","AUC LGBM Seed 2000: 26.4579\n","\n","Seed: 2503\n","\n","LGBM Fold 1 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021572 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.033037\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4394\tvalid_1's rmse: 26.4946\n","[500]\ttraining's rmse: 26.4227\tvalid_1's rmse: 26.4938\n","[750]\ttraining's rmse: 26.4073\tvalid_1's rmse: 26.494\n","Early stopping, best iteration is:\n","[492]\ttraining's rmse: 26.4232\tvalid_1's rmse: 26.4938\n","LGBM Fold 1 RMSE: 26.4938, Avg RMSE: 26.4596\n","\n","LGBM Fold 2 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021903 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.068350\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4414\tvalid_1's rmse: 26.4813\n","[500]\ttraining's rmse: 26.4247\tvalid_1's rmse: 26.4802\n","[750]\ttraining's rmse: 26.409\tvalid_1's rmse: 26.4799\n","[1000]\ttraining's rmse: 26.3947\tvalid_1's rmse: 26.4801\n","[1250]\ttraining's rmse: 26.3805\tvalid_1's rmse: 26.4802\n","Early stopping, best iteration is:\n","[874]\ttraining's rmse: 26.4018\tvalid_1's rmse: 26.4798\n","LGBM Fold 2 RMSE: 26.4798, Avg RMSE: 26.4605\n","\n","LGBM Fold 3 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021331 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.024250\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4195\tvalid_1's rmse: 26.6734\n","[500]\ttraining's rmse: 26.4033\tvalid_1's rmse: 26.6731\n","[750]\ttraining's rmse: 26.3885\tvalid_1's rmse: 26.673\n","[1000]\ttraining's rmse: 26.3737\tvalid_1's rmse: 26.6735\n","Early stopping, best iteration is:\n","[697]\ttraining's rmse: 26.3915\tvalid_1's rmse: 26.6729\n","LGBM Fold 3 RMSE: 26.6729, Avg RMSE: 26.4698\n","\n","LGBM Fold 4 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022455 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.035862\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4569\tvalid_1's rmse: 26.3364\n","[500]\ttraining's rmse: 26.4408\tvalid_1's rmse: 26.3368\n","[750]\ttraining's rmse: 26.4261\tvalid_1's rmse: 26.3384\n","Early stopping, best iteration is:\n","[357]\ttraining's rmse: 26.4498\tvalid_1's rmse: 26.3359\n","LGBM Fold 4 RMSE: 26.3359, Avg RMSE: 26.4642\n","\n","LGBM Fold 5 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021588 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.022749\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4443\tvalid_1's rmse: 26.4518\n","[500]\ttraining's rmse: 26.4279\tvalid_1's rmse: 26.4505\n","[750]\ttraining's rmse: 26.4128\tvalid_1's rmse: 26.4506\n","[1000]\ttraining's rmse: 26.3983\tvalid_1's rmse: 26.4508\n","Early stopping, best iteration is:\n","[670]\ttraining's rmse: 26.4176\tvalid_1's rmse: 26.4504\n","LGBM Fold 5 RMSE: 26.4504, Avg RMSE: 26.4636\n","\n","LGBM Fold 6 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022222 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.036350\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4471\tvalid_1's rmse: 26.4233\n","[500]\ttraining's rmse: 26.4306\tvalid_1's rmse: 26.4226\n","[750]\ttraining's rmse: 26.4153\tvalid_1's rmse: 26.424\n","Early stopping, best iteration is:\n","[408]\ttraining's rmse: 26.4364\tvalid_1's rmse: 26.4225\n","LGBM Fold 6 RMSE: 26.4225, Avg RMSE: 26.4620\n","\n","LGBM Fold 7 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021495 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.041217\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4586\tvalid_1's rmse: 26.3201\n","[500]\ttraining's rmse: 26.4424\tvalid_1's rmse: 26.3205\n","[750]\ttraining's rmse: 26.4277\tvalid_1's rmse: 26.3217\n","Early stopping, best iteration is:\n","[265]\ttraining's rmse: 26.4576\tvalid_1's rmse: 26.3201\n","LGBM Fold 7 RMSE: 26.3201, Avg RMSE: 26.4568\n","\n","LGBM Fold 8 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021849 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.019553\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.446\tvalid_1's rmse: 26.437\n","[500]\ttraining's rmse: 26.4294\tvalid_1's rmse: 26.4358\n","[750]\ttraining's rmse: 26.4143\tvalid_1's rmse: 26.4361\n","Early stopping, best iteration is:\n","[449]\ttraining's rmse: 26.4326\tvalid_1's rmse: 26.4357\n","LGBM Fold 8 RMSE: 26.4357, Avg RMSE: 26.4560\n","\n","LGBM Fold 9 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021486 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.022251\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4433\tvalid_1's rmse: 26.4633\n","[500]\ttraining's rmse: 26.4271\tvalid_1's rmse: 26.4638\n","[750]\ttraining's rmse: 26.4121\tvalid_1's rmse: 26.4645\n","Early stopping, best iteration is:\n","[309]\ttraining's rmse: 26.4395\tvalid_1's rmse: 26.4632\n","LGBM Fold 9 RMSE: 26.4632, Avg RMSE: 26.4563\n","\n","LGBM Fold 10 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022879 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.045375\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.438\tvalid_1's rmse: 26.5068\n","[500]\ttraining's rmse: 26.4216\tvalid_1's rmse: 26.5055\n","[750]\ttraining's rmse: 26.4068\tvalid_1's rmse: 26.5055\n","[1000]\ttraining's rmse: 26.3923\tvalid_1's rmse: 26.5055\n","[1250]\ttraining's rmse: 26.3783\tvalid_1's rmse: 26.5056\n","Early stopping, best iteration is:\n","[880]\ttraining's rmse: 26.3992\tvalid_1's rmse: 26.5054\n","LGBM Fold 10 RMSE: 26.5054, Avg RMSE: 26.4579\n","AUC LGBM Seed 2503: 26.4579\n","\n","Seed: 1511\n","\n","LGBM Fold 1 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021531 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.031658\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4638\tvalid_1's rmse: 26.2792\n","[500]\ttraining's rmse: 26.447\tvalid_1's rmse: 26.2791\n","[750]\ttraining's rmse: 26.432\tvalid_1's rmse: 26.2795\n","Early stopping, best iteration is:\n","[307]\ttraining's rmse: 26.4598\tvalid_1's rmse: 26.2788\n","LGBM Fold 1 RMSE: 26.2788, Avg RMSE: 26.4521\n","\n","LGBM Fold 2 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022984 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.029579\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.44\tvalid_1's rmse: 26.4928\n","[500]\ttraining's rmse: 26.4236\tvalid_1's rmse: 26.4927\n","[750]\ttraining's rmse: 26.4086\tvalid_1's rmse: 26.4938\n","Early stopping, best iteration is:\n","[355]\ttraining's rmse: 26.4329\tvalid_1's rmse: 26.4921\n","LGBM Fold 2 RMSE: 26.4921, Avg RMSE: 26.4534\n","\n","LGBM Fold 3 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022870 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.037618\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4492\tvalid_1's rmse: 26.4074\n","[500]\ttraining's rmse: 26.4327\tvalid_1's rmse: 26.4072\n","[750]\ttraining's rmse: 26.4177\tvalid_1's rmse: 26.4079\n","Early stopping, best iteration is:\n","[400]\ttraining's rmse: 26.4391\tvalid_1's rmse: 26.4071\n","LGBM Fold 3 RMSE: 26.4071, Avg RMSE: 26.4520\n","\n","LGBM Fold 4 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022263 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.034584\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4328\tvalid_1's rmse: 26.5507\n","[500]\ttraining's rmse: 26.4167\tvalid_1's rmse: 26.5513\n","[750]\ttraining's rmse: 26.4023\tvalid_1's rmse: 26.5514\n","Early stopping, best iteration is:\n","[313]\ttraining's rmse: 26.4285\tvalid_1's rmse: 26.5504\n","LGBM Fold 4 RMSE: 26.5504, Avg RMSE: 26.4549\n","\n","LGBM Fold 5 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021105 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.026700\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4419\tvalid_1's rmse: 26.4732\n","[500]\ttraining's rmse: 26.4251\tvalid_1's rmse: 26.4725\n","[750]\ttraining's rmse: 26.4103\tvalid_1's rmse: 26.4717\n","[1000]\ttraining's rmse: 26.3961\tvalid_1's rmse: 26.472\n","Early stopping, best iteration is:\n","[705]\ttraining's rmse: 26.413\tvalid_1's rmse: 26.4717\n","LGBM Fold 5 RMSE: 26.4717, Avg RMSE: 26.4554\n","\n","LGBM Fold 6 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022865 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.032005\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4378\tvalid_1's rmse: 26.5067\n","[500]\ttraining's rmse: 26.4214\tvalid_1's rmse: 26.5068\n","[750]\ttraining's rmse: 26.4066\tvalid_1's rmse: 26.5072\n","Early stopping, best iteration is:\n","[368]\ttraining's rmse: 26.4299\tvalid_1's rmse: 26.5066\n","LGBM Fold 6 RMSE: 26.5066, Avg RMSE: 26.4568\n","\n","LGBM Fold 7 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021465 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.049478\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4437\tvalid_1's rmse: 26.4561\n","[500]\ttraining's rmse: 26.4273\tvalid_1's rmse: 26.4567\n","Early stopping, best iteration is:\n","[143]\ttraining's rmse: 26.4519\tvalid_1's rmse: 26.4556\n","LGBM Fold 7 RMSE: 26.4556, Avg RMSE: 26.4568\n","\n","LGBM Fold 8 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021723 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.046400\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4418\tvalid_1's rmse: 26.4724\n","[500]\ttraining's rmse: 26.4257\tvalid_1's rmse: 26.472\n","[750]\ttraining's rmse: 26.411\tvalid_1's rmse: 26.4725\n","Early stopping, best iteration is:\n","[404]\ttraining's rmse: 26.4318\tvalid_1's rmse: 26.4716\n","LGBM Fold 8 RMSE: 26.4716, Avg RMSE: 26.4571\n","\n","LGBM Fold 9 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021635 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.030467\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4461\tvalid_1's rmse: 26.4359\n","[500]\ttraining's rmse: 26.4298\tvalid_1's rmse: 26.4353\n","[750]\ttraining's rmse: 26.4143\tvalid_1's rmse: 26.4355\n","Early stopping, best iteration is:\n","[398]\ttraining's rmse: 26.4363\tvalid_1's rmse: 26.4349\n","LGBM Fold 9 RMSE: 26.4349, Avg RMSE: 26.4566\n","\n","LGBM Fold 10 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021803 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.030504\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4376\tvalid_1's rmse: 26.515\n","[500]\ttraining's rmse: 26.4215\tvalid_1's rmse: 26.5145\n","[750]\ttraining's rmse: 26.4067\tvalid_1's rmse: 26.5146\n","Early stopping, best iteration is:\n","[384]\ttraining's rmse: 26.4286\tvalid_1's rmse: 26.5143\n","LGBM Fold 10 RMSE: 26.5143, Avg RMSE: 26.4580\n","AUC LGBM Seed 1511: 26.4580\n","\n","Seed: 2604\n","\n","LGBM Fold 1 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021248 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.043557\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4423\tvalid_1's rmse: 26.471\n","[500]\ttraining's rmse: 26.4259\tvalid_1's rmse: 26.4712\n","[750]\ttraining's rmse: 26.4107\tvalid_1's rmse: 26.472\n","Early stopping, best iteration is:\n","[352]\ttraining's rmse: 26.4354\tvalid_1's rmse: 26.4705\n","LGBM Fold 1 RMSE: 26.4705, Avg RMSE: 26.4583\n","\n","LGBM Fold 2 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022272 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.020219\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4396\tvalid_1's rmse: 26.4934\n","[500]\ttraining's rmse: 26.4231\tvalid_1's rmse: 26.4946\n","Early stopping, best iteration is:\n","[216]\ttraining's rmse: 26.442\tvalid_1's rmse: 26.4933\n","LGBM Fold 2 RMSE: 26.4933, Avg RMSE: 26.4592\n","\n","LGBM Fold 3 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022289 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.039188\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4363\tvalid_1's rmse: 26.5233\n","[500]\ttraining's rmse: 26.4198\tvalid_1's rmse: 26.5236\n","[750]\ttraining's rmse: 26.405\tvalid_1's rmse: 26.5229\n","[1000]\ttraining's rmse: 26.3913\tvalid_1's rmse: 26.5226\n","[1250]\ttraining's rmse: 26.3777\tvalid_1's rmse: 26.5227\n","Early stopping, best iteration is:\n","[891]\ttraining's rmse: 26.3973\tvalid_1's rmse: 26.5225\n","LGBM Fold 3 RMSE: 26.5225, Avg RMSE: 26.4606\n","\n","LGBM Fold 4 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021412 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471747, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.026330\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4373\tvalid_1's rmse: 26.5165\n","[500]\ttraining's rmse: 26.4207\tvalid_1's rmse: 26.5156\n","[750]\ttraining's rmse: 26.4055\tvalid_1's rmse: 26.5154\n","[1000]\ttraining's rmse: 26.3909\tvalid_1's rmse: 26.5152\n","[1250]\ttraining's rmse: 26.3768\tvalid_1's rmse: 26.5149\n","[1500]\ttraining's rmse: 26.3632\tvalid_1's rmse: 26.5156\n","Early stopping, best iteration is:\n","[1206]\ttraining's rmse: 26.3792\tvalid_1's rmse: 26.5149\n","LGBM Fold 4 RMSE: 26.5149, Avg RMSE: 26.4619\n","\n","LGBM Fold 5 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055357 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.047611\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4293\tvalid_1's rmse: 26.5844\n","[500]\ttraining's rmse: 26.4125\tvalid_1's rmse: 26.5841\n","[750]\ttraining's rmse: 26.3974\tvalid_1's rmse: 26.5853\n","Early stopping, best iteration is:\n","[424]\ttraining's rmse: 26.4175\tvalid_1's rmse: 26.584\n","LGBM Fold 5 RMSE: 26.5840, Avg RMSE: 26.4646\n","\n","LGBM Fold 6 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022279 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.043630\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4603\tvalid_1's rmse: 26.3083\n","[500]\ttraining's rmse: 26.4441\tvalid_1's rmse: 26.3074\n","[750]\ttraining's rmse: 26.4291\tvalid_1's rmse: 26.3081\n","Early stopping, best iteration is:\n","[379]\ttraining's rmse: 26.4516\tvalid_1's rmse: 26.3074\n","LGBM Fold 6 RMSE: 26.3074, Avg RMSE: 26.4612\n","\n","LGBM Fold 7 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022172 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.020001\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4511\tvalid_1's rmse: 26.3918\n","[500]\ttraining's rmse: 26.4348\tvalid_1's rmse: 26.391\n","[750]\ttraining's rmse: 26.4199\tvalid_1's rmse: 26.3912\n","[1000]\ttraining's rmse: 26.406\tvalid_1's rmse: 26.3919\n","Early stopping, best iteration is:\n","[598]\ttraining's rmse: 26.4288\tvalid_1's rmse: 26.3909\n","LGBM Fold 7 RMSE: 26.3909, Avg RMSE: 26.4597\n","\n","LGBM Fold 8 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044790 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.010104\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4439\tvalid_1's rmse: 26.4556\n","[500]\ttraining's rmse: 26.4272\tvalid_1's rmse: 26.4553\n","[750]\ttraining's rmse: 26.4119\tvalid_1's rmse: 26.4561\n","Early stopping, best iteration is:\n","[451]\ttraining's rmse: 26.4303\tvalid_1's rmse: 26.4552\n","LGBM Fold 8 RMSE: 26.4552, Avg RMSE: 26.4596\n","\n","LGBM Fold 9 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021509 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.058957\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4466\tvalid_1's rmse: 26.4283\n","[500]\ttraining's rmse: 26.4301\tvalid_1's rmse: 26.4279\n","[750]\ttraining's rmse: 26.4151\tvalid_1's rmse: 26.4287\n","Early stopping, best iteration is:\n","[393]\ttraining's rmse: 26.4369\tvalid_1's rmse: 26.4275\n","LGBM Fold 9 RMSE: 26.4275, Avg RMSE: 26.4589\n","\n","LGBM Fold 10 - 10\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033394 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2295\n","[LightGBM] [Info] Number of data points in the train set: 471748, number of used features: 9\n","[LightGBM] [Info] Start training from score 119.039396\n","Training until validation scores don't improve for 500 rounds\n","[250]\ttraining's rmse: 26.4479\tvalid_1's rmse: 26.4179\n","[500]\ttraining's rmse: 26.4315\tvalid_1's rmse: 26.4183\n","[750]\ttraining's rmse: 26.4166\tvalid_1's rmse: 26.4191\n","Early stopping, best iteration is:\n","[287]\ttraining's rmse: 26.4454\tvalid_1's rmse: 26.4176\n","LGBM Fold 10 RMSE: 26.4176, Avg RMSE: 26.4581\n","AUC LGBM Seed 2604: 26.4581\n"]}],"source":["for s in SEEDS:\n","    print(f\"\\nSeed: {s}\")\n","    np.random.seed(s)\n","    name_seed = f\"Seed_{s}\"\n","    sub_seeds[name_seed] = 0\n","    if dt.shape[0] == 0:\n","        raise ValueError(\"Training dataset (dt) is empty. Check data loading or preprocessing steps.\")\n","    kf = KFold(n_splits=10, shuffle=True, random_state=s)\n","    pred_lgbm_total = np.zeros(len(dtest))\n","    sub_temp = pd.DataFrame({'id': sub['id']})\n","    auc_lgbm_total = 0\n","\n","    for i_fold, (train_idx, val_idx) in enumerate(kf.split(dt), 1):\n","        print(f\"\\nLGBM Fold {i_fold} - 10\")\n","        X_train, y_train = dt.iloc[train_idx].drop(columns='id'), Y[train_idx]\n","        X_val, y_val = dt.iloc[val_idx].drop(columns='id'), Y[val_idx]\n","\n","        # LightGBM model\n","        lgb_params = {\n","            'random_state': 0,\n","            'n_estimators': 4500,\n","            'learning_rate': 0.005,\n","            'boosting_type': 'gbdt',\n","            'objective': 'regression',\n","            'metric': 'rmse'\n","        }\n","\n","        model = LGBMRegressor(**lgb_params)\n","        model.fit(\n","            X_train, y_train,\n","            eval_set=[(X_train, y_train), (X_val, y_val)],\n","            eval_metric='rmse',\n","            callbacks=[early_stopping(stopping_rounds=500), log_evaluation(period=250)]\n","        )\n","\n","        # Predictions\n","        test_lgbm = model.predict(X_val)\n","        oof.loc[val_idx, f\"LGBM_Seed_{s}\"] = test_lgbm\n","        auc_lgbm = rmse(y_val, test_lgbm)\n","        auc_lgbm_total += auc_lgbm\n","        scores.append(auc_lgbm)\n","        print(f\"LGBM Fold {i_fold} RMSE: {auc_lgbm:.4f}, Avg RMSE: {np.mean(scores):.4f}\")\n","\n","        # Test predictions\n","        pred_lgbm = model.predict(dtest.drop(columns='id'))\n","        pred_lgbm_total += pred_lgbm\n","        sub_temp[f\"Seed_s{s}_Fold_{i_fold}\"] = pred_lgbm\n","        sub_seeds[name_seed] += pred_lgbm / 10\n","\n","        # Feature importance\n","        importance = pd.DataFrame({\n","            'Feature': X_train.columns,\n","            'Importance': model.feature_importances_\n","        })\n","        importance.to_csv(\"ImportanciaLGBM_v1.csv\", index=False)\n","        free()\n","\n","    pred_lgbm_total /= 10\n","    print(f\"AUC LGBM Seed {s}: {np.mean(scores):.4f}\")"]},{"cell_type":"markdown","id":"13943b74","metadata":{"papermill":{"duration":0.024638,"end_time":"2025-09-05T16:42:26.63201","exception":false,"start_time":"2025-09-05T16:42:26.607372","status":"completed"},"tags":[]},"source":["## Save Outputs\n","Saves predictions in multiple formats: mean, median, fold-wise, OOF, and seed-wise."]},{"cell_type":"code","execution_count":21,"id":"1eb1ae62","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:42:26.684643Z","iopub.status.busy":"2025-09-05T16:42:26.683873Z","iopub.status.idle":"2025-09-05T16:42:37.250232Z","shell.execute_reply":"2025-09-05T16:42:37.24889Z"},"papermill":{"duration":10.594247,"end_time":"2025-09-05T16:42:37.252399","exception":false,"start_time":"2025-09-05T16:42:26.658152","status":"completed"},"tags":[]},"outputs":[],"source":["# Save Outputs\n","sub.iloc[:, 1] = sub_temp.iloc[:, 1:].mean(axis=1)\n","sub.to_csv(\"subLGBMFit_v1.csv\", index=False)\n","\n","sub.iloc[:, 1] = sub_temp.iloc[:, 1:].median(axis=1)\n","sub.to_csv(\"subLGBMFitMedian_v1.csv\", index=False)\n","\n","sub_temp.to_csv(\"subFoldLGBMFit_v1.csv\", index=False)\n","oof.to_csv(\"OOF_LGBMFit_v1.csv\", index=False)\n","sub_seeds.to_csv(\"subSeedsLGBM_v1.csv\", index=False)"]},{"cell_type":"markdown","id":"4d49098d","metadata":{"papermill":{"duration":0.024415,"end_time":"2025-09-05T16:42:37.302035","exception":false,"start_time":"2025-09-05T16:42:37.27762","status":"completed"},"tags":[]},"source":["## Evaluate Performance\n","Prints RMSE for each seed and the mean RMSE across seeds."]},{"cell_type":"code","execution_count":22,"id":"d9feb21b","metadata":{"execution":{"iopub.execute_input":"2025-09-05T16:42:37.352995Z","iopub.status.busy":"2025-09-05T16:42:37.352652Z","iopub.status.idle":"2025-09-05T16:42:37.387416Z","shell.execute_reply":"2025-09-05T16:42:37.386076Z"},"papermill":{"duration":0.062315,"end_time":"2025-09-05T16:42:37.38906","exception":false,"start_time":"2025-09-05T16:42:37.326745","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE Seed 1975: 26.4583\n","RMSE Seed 2000: 26.4578\n","RMSE Seed 2503: 26.4581\n","RMSE Seed 1511: 26.4584\n","RMSE Seed 2604: 26.4585\n","Mean RMSE: 26.4582\n"]}],"source":["# Evaluate Performance\n","for s in SEEDS:\n","    print(f\"RMSE Seed {s}: {rmse(oof['target'], oof[f'LGBM_Seed_{s}']):.4f}\")\n","\n","auc_mean = np.mean([rmse(oof['target'], oof[f'LGBM_Seed_{s}']) for s in SEEDS])\n","print(f\"Mean RMSE: {auc_mean:.4f}\")"]},{"cell_type":"code","execution_count":null,"id":"b028e299","metadata":{"papermill":{"duration":0.024213,"end_time":"2025-09-05T16:42:37.438025","exception":false,"start_time":"2025-09-05T16:42:37.413812","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a376e70d","metadata":{"papermill":{"duration":0.024447,"end_time":"2025-09-05T16:42:37.487976","exception":false,"start_time":"2025-09-05T16:42:37.463529","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"bbe8a1cd","metadata":{"papermill":{"duration":0.024445,"end_time":"2025-09-05T16:42:37.537333","exception":false,"start_time":"2025-09-05T16:42:37.512888","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"d429ca0d","metadata":{"papermill":{"duration":0.024694,"end_time":"2025-09-05T16:42:37.586348","exception":false,"start_time":"2025-09-05T16:42:37.561654","status":"completed"},"tags":[]},"outputs":[],"source":["\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":13345277,"sourceId":91720,"sourceType":"competition"}],"dockerImageVersionId":31089,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":2081.570977,"end_time":"2025-09-05T16:42:38.536764","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-09-05T16:07:56.965787","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}